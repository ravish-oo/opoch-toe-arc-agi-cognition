# WO-6 — Quotas K (Paid) + Y₀ Selection

## Anchors to read first

* ` @docs/anchors/00_math_spec.md ` — §4 *Per-Type Quotas (Paid Ledger)*: K comes **only** from training outputs; Σ cuts; ∑₍c₎K[S,c]=|S|; never mint from inputs. 
* ` @docs/anchors/01_math_spec_addendum.md ` — reiterates “never read quotas from X” and the receipts you should log (palette, K, Σ, idempotence later). 

## Goal

1. **Deterministically select one training output (Y₀)** to read quotas from, using a fixed policy tied only to palettes (no input-based minting).
2. **Compute per-type color quotas (K_{S,c})** on Π(Y₀).
3. Emit receipts proving:

   * why Y₀ was chosen,
   * that K is **valid** (per type sum equals block size), and
   * that no quota information has been read from inputs.

No FREE logic, no transport, no fill here—just the paid ledger K.

---

## Interfaces (frozen)

```python
# arc/quotas.py
from typing import Dict, Tuple, Any, List
import numpy as np

def choose_Y0(task: Dict[str, Any]) -> int:
    """
    Deterministically choose which training output provides quotas.
    Policy (v0):
      1) Let P_test = nonzero palette of test input.
      2) Among training outputs, pick the first whose nonzero palette == P_test.
      3) If none match, pick the first training output (index 0).
    Returns: Y0 index in task["train"].
    """

def quotas(Y0: np.ndarray, T0: np.ndarray, C: int) -> Dict[int, np.ndarray]:
    """
    Count per-type color quotas on Π(Y0).
    Returns: K mapping type_id -> length-C vector of counts (np.int64).
    Enforces ∑_c K[S,c] == |S|.
    """
```

`C` is the fixed ARC palette size (10 in Kaggle ARC). K vectors must be length `C` even if some colors don’t appear (zeros included).

---

## Exact libraries & functions to use (no custom algos)

**Palette computations (Y₀ selection)**

* Unique & counts (documented): `numpy.unique(a, return_counts=True)` (sorted unique + counts) ([NumPy][1]).
* Count of nonzeros (if you need it): `numpy.count_nonzero(a)` (documented) ([NumPy][2]).
* For set–like comparisons: convert `np.unique` results to Python `set` and compare.

**Quotas per type**

* For each type id `S`, build a mask `T0==S` and count colors with **documented** NumPy primitives:

  * `numpy.bincount(colors, minlength=C)` to get a length-C vector; input must be non-negative integers (true for ARC colors) ([NumPy][3]).
  * Alternatively, `numpy.unique(colors, return_counts=True)` then scatter into a zeroed length-C vector; both APIs are official and stable ([NumPy][1]).
* Totals check: `K[S].sum() == mask.sum()` (or `np.count_nonzero(mask)`).

**Runner/receipts plumbing**

* CLI: stdlib **`argparse`** for `--mode quotas-receipts`, `--challenges`, `--out` (official docs) ([Python documentation][4]).
* Paths: **`pathlib.Path`** for file I/O (official docs) ([Python documentation][5]).
* JSON Lines: one JSON object **per line**, UTF-8; follow JSONL spec’s three rules ([JSON Lines][6]).
* Hashes (optional integrity fields): **`hashlib.sha256`** for deterministic hex digests ([Python documentation][7]).

> We deliberately **do not** introduce pandas or hand-rolled grouping—NumPy’s `unique`/`bincount` already cover everything and are well-documented.

---

## Deterministic Y₀ policy (v0, frozen)

1. Compute **nonzero palette** for test input `X*`:
   `P_test = set(np.unique(X_star)) - {0}`.
2. For each training pair in **index order** (0..m-1), compute `P_i = set(np.unique(Y_i)) - {0}`.
3. Pick the **first** index `i` such that `P_i == P_test`.
4. If none match, pick index **0**.

Receipts must record `P_test`, each `P_i` in order (or at least the match index), and the **exact reason** string: `"reason": "palette_match"` or `"reason": "fallback_first"`.

This selection uses test palette **only to choose Y₀**; it never reads quota numbers from inputs, so A0 remains intact.

---

## Receipts (first-class)

Per task, write **one** JSON object (JSONL) with everything needed to audit WO-6:

```json
{
  "task_id": "025d127b",
  "quotas": {
    "C": 10,
    "y0_index": 2,
    "y0_reason": "palette_match",      // or "fallback_first"
    "palette_test_nonzero": [2,7],
    "palette_train_nonzero": [
      [6], [4], [2], [2,7]             // per training output, order preserved
    ],
    "K": {
      "1": [0,0,5,0,0,0,0,0,0,0],      // type id "1" -> vector of length C
      "2": [12,0,0,0,0,0,0,0,0,0]
    },
    "sum_checks": {                    // ∑_c K[S,c] == |S|
      "1": {"size": 5, "sum": 5, "pass": true},
      "2": {"size": 12, "sum": 12, "pass": true}
    }
  }
}
```

* `K` keys are **stringified** type ids for JSON. Vectors must be length-`C`.
* `sum_checks[*].pass` must be `true` for all types.
* Optional integrity: include `sha256_T0` (hash of Π(Y₀)), or `sha256_K` (hash over the concatenated quota vectors) computed via `hashlib.sha256` ([Python documentation][7]).

---

## Runner changes

Add a mode:

```bash
python -m arc.solve \
  --mode quotas-receipts \
  --challenges /mnt/data/arc-agi_training_challenges.json \
  --out outputs/receipts_wo6.jsonl
```

Behavior per task:

1. Call `choose_Y0(task)` and record `y0_index`, `reason`, `P_test`, and per-Y palettes.
2. Compute `T0 = Π(Y₀)` using WO-1, then `K = quotas(Y₀, T0, C=10)`.
3. Emit the JSONL record above.

Keep JSON Lines discipline (UTF-8, one JSON per line) per spec ([JSON Lines][6]).

---

## Reviewer instructions (all 1000 tasks)

**Run**

```bash
python -m arc.solve \
  --mode quotas-receipts \
  --challenges /mnt/data/arc-agi_training_challenges.json \
  --out outputs/receipts_wo6.jsonl
```

**Assert**

* The selection policy is followed **exactly**:

  * If any training `P_i` equals `P_test`, `y0_index` is the smallest such `i` and `y0_reason == "palette_match"`.
  * Else `y0_index == 0` with `y0_reason == "fallback_first"`.
* For every type `S` in `T0`, `sum_checks[S].pass == true` (i.e., `K[S].sum() == |S|`).
* `K` contains vectors of length `C=10` (zeros where colors absent).
* There is **no** field derived from test **counts**; the test palette is used **only** to choose Y₀.

**Classify gaps vs bugs**

* There are **no spec gaps** in WO-6—every task must produce a valid `K`.
* Any failure is an implementation bug (palette extraction, Π call, or `bincount`/`unique` usage).

---

## Performance (CPU)

* Palette: `np.unique` over small grids is trivial (C-level) ([NumPy][1]).
* Quotas: `np.bincount(..., minlength=C)` per type id is O(|S|) and vectorized in C; ARC grids are small ([NumPy][3]).
* JSONL writing and hashlib are negligible cost ([JSON Lines][6]).
* **No optimizations** beyond these; correctness first.

---

## Acceptance criteria (green = WO-6 done)

* ✔ Runner completes on all 1000 tasks; emits one quotas receipt per task.
* ✔ Y₀ chosen deterministically per policy; reason recorded.
* ✔ `K` length-C vectors produced for all types; `sum_checks` pass universally.
* ✔ Deterministic across runs (same Y₀ index, same K).
* ✔ Code ≤ ~150 LOC in `arc/quotas.py` + small runner plumbing; uses only cited APIs (`np.unique`, `np.bincount`, `argparse`, `pathlib`, JSONL, `hashlib`).

---

[1]: https://numpy.org/doc/stable/reference/generated/numpy.unique.html?utm_source=chatgpt.com "numpy.unique — NumPy v2.3 Manual"
[2]: https://numpy.org/devdocs/reference/generated/numpy.count_nonzero.html?utm_source=chatgpt.com "numpy.count_nonzero — NumPy v2.4.dev0 Manual"
[3]: https://numpy.org/doc/2.1/reference/generated/numpy.bincount.html?utm_source=chatgpt.com "numpy.bincount — NumPy v2.1 Manual"
[4]: https://docs.python.org/3/library/argparse.html?utm_source=chatgpt.com "argparse — Parser for command-line options, arguments and ..."
[5]: https://docs.python.org/3/library/pathlib.html?utm_source=chatgpt.com "pathlib — Object-oriented filesystem paths"
[6]: https://jsonlines.org/?utm_source=chatgpt.com "JSON Lines"
[7]: https://docs.python.org/3/library/hashlib.html?utm_source=chatgpt.com "hashlib — Secure hashes and message digests"
