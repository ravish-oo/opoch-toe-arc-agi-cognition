# WO-8 — v0 Runner (Batch + Audit)

## Anchors to read first

* ` @docs/anchors/00_math_spec.md ` (§0–§6: Π → FREE → K → meet; exact equality).
* ` @docs/anchors/01_math_spec_addendum.md ` (FREE proofs on **types**; intersection across trainings; receipts).

---

## Goal

Run the **entire v0 pipeline** end-to-end on the corpus, **without** re-implementing any WO logic in the runner:

> For each task:
> **WO-4** `prove_free` → **WO-5** `transport_types` → **WO-6** `choose_Y0` + `quotas` → **WO-7** `fill_by_rank` (+ `idempotence_check`) → write predictions + receipts → optional GT triage.

---

## Strict constraints on `solve.py` (critical)

* The runner is **thin orchestration only**.
* It **must not** call per-family verifiers directly (no calls to `verify_*` from WO-3*).
* It **must not** duplicate WO logic (no re-picks, no custom intersections, no DIY diagnosis).
* It **must** call the **module APIs** exactly as listed below, in this order, and stream receipts.

If the total runner glue exceeds ~60 LOC (excluding CLI boilerplate), you’re doing too much.

---

## Exact libraries to use (no custom algos)

* `argparse` (CLI), `pathlib.Path` (paths), `json` (I/O), `hashlib` (sha256).
* `numpy` only for equality checks and dtype casts in the triage compare step (no new numerics beyond that).
* **JSON Lines** for receipts and report (one JSON object per line, UTF-8).

No pandas, no hand-rolled verifiers in the runner.

---

## Module API calls you MUST use (and only these)

* **WO-4**: `arc.free_prove.prove_free(task: Dict[str,Any]) -> ("FREE_PROVEN", payload) | ("FREE_UNPROVEN", payload)`

  * read `payload["chosen"]` when proven (tuple like `("identity", None)` or `("tile",(sh,sw))`)
* **WO-5**: `arc.transport.transport_types(T_Y0: np.ndarray, free_tuple: Tuple[str,Tuple], X_test_shape: Tuple[int,int], X_test: np.ndarray|None) -> (T_test: np.ndarray, parent_of: Dict[int,int])`
* **WO-6**:

  * `y0_index = arc.quotas.choose_Y0(task)`
  * `T_Y0,_ = arc.pi.types_from_output(Y0)`
  * `K = arc.quotas.quotas(Y0, T_Y0, C=10)`
* **WO-7**:

  * `Y_star = arc.fill.fill_by_rank(T_test, parent_of, K, C=10)`
  * `idempotent = arc.fill.idempotence_check(Y_star, C=10)`

> The runner may not change these interfaces and may not call lower-level verifiers directly.

---

## CLI and modes (argparse subcommands)

* `v0`: end-to-end run.
* `audit`: print receipts for a given `--id`.

**Arguments for `v0`:**

* `--challenges` (Path): ARC challenges JSON
* `--pred` (Path): write predictions JSON
* `--receipts` (Path): write receipts JSONL (append one JSON per task)
* `--report` (Path): write triage summary JSONL
* `--with-gt` (flag) and `--gt` (Path) optional: ground-truth JSON to compute MATCH/MISMATCH/ SKIPPED triage

**Arguments for `audit`:**

* `--id` task id
* `--receipts` receipts JSONL path

---

## Runner pipeline (exact steps)

For each `task_id, task`:

1. **WO-4** — prove FREE

   ```py
   status4, payload4 = prove_free(task)
   if status4 == "FREE_UNPROVEN":
       write triage:
         {"task_id":…, "triage":{"status":"SKIPPED", "reason":"FREE_UNPROVEN"}}
       continue
   chosen = payload4["chosen"]             # e.g. ("identity", None)
   free_tuple = chosen if chosen[1] is not None else (chosen[0],)
   ```

2. **WO-6** — choose Y₀ and compute quotas

   ```py
   y0_index = choose_Y0(task)
   Y0 = np.array(task["train"][y0_index]["output"], dtype=np.int32)
   T_Y0, _ = types_from_output(Y0)
   K = quotas(Y0, T_Y0, C=10)
   ```

3. **WO-5** — transport types

   ```py
   X_test = np.array(task["test"][0]["input"], dtype=np.int32)
   T_test, parent_of = transport_types(T_Y0, free_tuple, X_test.shape, X_test)
   ```

4. **WO-7** — fill + idempotence

   ```py
   Y_star = fill_by_rank(T_test, parent_of, K, C=10)
   idempotent = idempotence_check(Y_star, C=10)
   assert idempotent is True
   ```

5. **Write prediction** (append to list; later dump as JSON)
   `{"id": task_id, "output": Y_star.tolist(), "sha256": sha256(Y_star)}`

6. **Write receipts**

   * You already write receipts per WO in each module.
   * WO-8 adds one **task-level triage** object (see below).

7. **If `--with-gt`** compare exact equality and triage using **only WO-4** on `(X*, GT)`:

   * Build a **synthetic task**: `{"train":[{"input": X_test, "output": GT}], "test":[{"input": X_test}]}`.
   * `gt_status, gt_payload = prove_free(synth_task)`; if `gt_status == "FREE_PROVEN"` set `gt_free = gt_payload["chosen"]` else `gt_free = None`.
   * Triage:

     * `MATCH` if `np.array_equal(Y_star, GT)`.
     * Else if **FREE_UNPROVEN** earlier → `SKIPPED/FREE_UNPROVEN`.
     * Else if `gt_free is None` or `gt_free != chosen` → `MISMATCH` with:

       * `reason="FREE_DIFFERS"` if `gt_free` is a different terminal (v1/v2 gap)
       * `reason="IMPLEMENTATION"` if any receipts from WO-5/6/7 were not green
     * Else if `gt_free == chosen` → `MISMATCH`, `reason="POLICY"` (e.g., Y₀ selection / tie); receipts remain green.

> **Do not** call individual family verifiers from the runner. **Always** reuse `prove_free` for GT diagnosis. This guarantees we use the same tested intersection + pick logic.

---

## Receipts (first-class)

* Continue emitting module receipts (WO-1..7).
* WO-8 appends **one task-level triage** JSON object per task:

```json
{
  "task_id": "…",
  "triage": {
    "status": "MATCH|MISMATCH|SKIPPED",
    "reason": "FREE_UNPROVEN|FREE_DIFFERS|POLICY|IMPLEMENTATION|null",
    "free_chosen": ["identity", null],
    "gt_free": ["tile", [3,3]],
    "sha256_prediction": "…",
    "sha256_gt": "…"
  }
}
```

* And writes a short **report.jsonl** with:

  * `{"metric":"counts_by_status", "MATCH":…, "MISMATCH":…, "SKIPPED":…}`
  * `{"metric":"mismatch_breakdown", "IMPLEMENTATION":…, "POLICY":…, "FREE_DIFFERS":…}`
  * `{"metric":"terminal_distribution", **terminal_counts }`
  * `{"metric":"frozen_order_echo", "order":["identity", ["h-mirror-concat","v-double","h-concat-dup","v-concat-dup"], "tile", "SBS-Y", "SBS-param"]}`

---

## Reviewer instructions

Run:

```bash
python -m arc.cli \
  --mode v0 \
  --challenges /mnt/data/arc-agi_training_challenges.json \
  --pred outputs/predictions.json \
  --receipts outputs/receipts_all.jsonl \
  --report outputs/report.jsonl \
  --with-gt --gt /mnt/data/arc-agi_training_solutions.json
```

Then report **exactly**:

1. **How many MATCH** (`status == "MATCH"`).
2. For all **MISMATCH**, the split by:

   * `IMPLEMENTATION` (some WO-5/6/7 receipt failed; code bug)
   * `POLICY` (gt_free == chosen; our pipeline OK but policy like Y₀ pick likely wrong)
   * `FREE_DIFFERS` (gt_free ≠ chosen; v1/v2 FREE family gap)
     Include 3–5 example task ids per bucket.
3. **How many SKIPPED (FREE_UNPROVEN)** — this is the v1/v2 backlog count.

This tells us, without guesswork, what to fix now vs what to add later.

---

## Pass criteria

* **600+** tasks processed end-to-end; no crashes; deterministic outputs.
* Predictions + receipts written; report written; audit works.
* Runner contains **no** new verifier logic; strictly calls the WOs.

---

## Anti-bloat checklist (enforced)

* [x] Over-specific & anchored (no new math in the runner).
* [x] Anchors cited.
* [x] Exact libs only: `argparse`, `pathlib`, `json`, `hashlib`, `numpy` for equality.
* [x] Receipts: triage + summary; JSONL one-object-per-line.
* [x] Runner changes: only subcommands `v0` and `audit`.
* [x] Reviewer guide: commands + what to report for MATCH/MISMATCH/SKIPPED.
* [x] No “optimizations”; no re-implementation of WOs; tiny glue only.

---

### One last time, for the implementer

> **Do not** write or call `_diagnose_gt` that pokes `verify_*` functions.
> **Do** call `prove_free` on `(X*, GT)` to diagnose GT.
> **Do not** expand `run_v0` beyond stitching calls to `prove_free → transport_types → choose_Y0/quotas → fill_by_rank`.
> **Do** let each WO write its receipts; the runner only appends triage + summary lines.
